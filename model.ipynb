{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7832e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install pdfplumber scikit-learn transformers accelerate\n",
    "\n",
    "import os, re, pdfplumber\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "NOT_FOUND = \"I couldn’t find that in the provided document.\"\n",
    "\n",
    "# Load small LLM\n",
    "gen = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device_map=\"auto\")\n",
    "\n",
    "def extract_text(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            text = f.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    elif ext == \".pdf\":\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            pages = [p.extract_text() or \"\" for p in pdf.pages]\n",
    "        text = \"\\n\\n\".join(pages)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .txt or .pdf\")\n",
    "    return text.strip()\n",
    "\n",
    "def chunk_text(text, max_chars=1500, overlap=200):\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    chunks = []\n",
    "    i, n = 0, len(text)\n",
    "    while i < n:\n",
    "        end = min(i + max_chars, n)\n",
    "        piece = text[i:end]\n",
    "        if end < n:\n",
    "            cut = piece.rfind(\". \")\n",
    "            if cut > max_chars * 0.6:\n",
    "                piece = piece[:cut+1]\n",
    "                end = i + cut + 1\n",
    "        piece = piece.strip()\n",
    "        if piece:\n",
    "            chunks.append(piece)\n",
    "        if end >= n:\n",
    "            break\n",
    "        i = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self, chunks):\n",
    "        self.chunks = chunks\n",
    "        self.vectorizer = TfidfVectorizer(lowercase=True, token_pattern=r\"[A-Za-z0-9]+\")\n",
    "        self.mat = self.vectorizer.fit_transform(chunks)\n",
    "    def search(self, query, k=4):\n",
    "        q = self.vectorizer.transform([query])\n",
    "        sims = cosine_similarity(q, self.mat)[0]\n",
    "        idxs = sims.argsort()[::-1][:k]\n",
    "        return [(int(i), float(sims[i]), self.chunks[int(i)]) for i in idxs]\n",
    "\n",
    "def build_prompt(question, contexts):\n",
    "    ctx = \"\\n\\n\".join([f\"[#{i+1}]\\n{c}\" for i,c in enumerate(contexts)])\n",
    "    return (\n",
    "        \"You are a careful assistant that answers using ONLY the provided context.\\n\"\n",
    "        f\"If not in the context, reply exactly: \\\"{NOT_FOUND}\\\"\\n\\n\"\n",
    "        f\"Context:\\n{ctx}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "def ask_question(question, retriever):\n",
    "    hits = retriever.search(question, k=4)\n",
    "    if not hits or hits[0][1] < 0.08:\n",
    "        return NOT_FOUND\n",
    "    contexts = [h[2] for h in hits]\n",
    "    prompt = build_prompt(question, contexts)\n",
    "    out = gen(prompt, max_new_tokens=256, temperature=0.0)\n",
    "    text = out[0][\"generated_text\"].strip()\n",
    "    return text if text else NOT_FOUND\n",
    "\n",
    "path = \"/content/test.txt\"  # change to your file\n",
    "text = extract_text(path)\n",
    "chunks = chunk_text(text)\n",
    "retriever = Retriever(chunks)\n",
    "\n",
    "print(f\"✅ Loaded {len(chunks)} chunks from {path}\")\n",
    "\n",
    "# Now loop questions in console\n",
    "while True:\n",
    "    q = input(\"Ask a question (or 'exit'): \").strip()\n",
    "    if q.lower() in (\"exit\", \"quit\"):\n",
    "        break\n",
    "    ans = ask_question(q, retriever)\n",
    "    print(\"Answer:\", ans)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
